{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Simulation study for conjugate gradients\n\nWe conduct in the following a simulation study illustrating the conjugate gradients algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\nimport numpy as np\nimport pandas as pd\nfrom scipy.sparse import dia_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport EarlyStopping as es\n\nsns.set_theme(style=\"ticks\")\nnp.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulation Setting\nTo make our results comparable, we use the same simulation setting as [Blanchard et al. (2018)](https://doi.org/10.1137/17M1154096) and [Stankewitz (2020)](https://doi.org/10.1214/20-EJS1747).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set parameters\nsample_size = 10000\nparameter_size = sample_size\nmax_iter = sample_size\nnoise_level = 0.01\ncritical_value = sample_size * (noise_level**2)\n\n# Create diagonal design matrices\nindices = np.arange(sample_size) + 1\ndesign = dia_matrix(np.diag(1 / (np.sqrt(indices))))\n\n# Create signals\nsignal_supersmooth = 5 * np.exp(-0.1 * indices)\nsignal_smooth = 5000 * np.abs(np.sin(0.01 * indices)) * indices ** (-1.6)\nsignal_rough = 250 * np.abs(np.sin(0.002 * indices)) * indices ** (-0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the SVD coefficients of the three signals.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(indices, signal_supersmooth, label=\"supersmooth signal\")\nplt.plot(indices, signal_smooth, label=\"smooth signal\")\nplt.plot(indices, signal_rough, label=\"rough signal\")\nplt.ylabel(\"Signal\")\nplt.xlabel(\"Index\")\nplt.ylim([-0.05, 1.6])\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monte Carlo Study\nWe simulate NUMBER_RUNS realisations of the Gaussian sequence space model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Specify number of Monte Carlo runs\nNUMBER_RUNS = 10\n\n# Set computation threshold\ncomputation_threshold = 0\n\n# Create observations for the three different signals\nnoise = np.random.normal(0, noise_level, (sample_size, NUMBER_RUNS))\nobservation_supersmooth = noise + (design @ signal_supersmooth)[:, None]\nobservation_smooth = noise + (design @ signal_smooth)[:, None]\nobservation_rough = noise + (design @ signal_rough)[:, None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We choose to interpolate linearly between the conjugate gradient estimates at integer iteration indices and create the models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set interpolation boolean\ninterpolation_boolean = True\n\n# Create models\nmodels_supersmooth = [\n    es.ConjugateGradients(\n        design,\n        observation_supersmooth[:, i],\n        true_signal=signal_supersmooth,\n        true_noise_level=noise_level,\n        interpolation=interpolation_boolean,\n        computation_threshold=computation_threshold,\n    )\n    for i in range(NUMBER_RUNS)\n]\nmodels_smooth = [\n    es.ConjugateGradients(\n        design,\n        observation_smooth[:, i],\n        true_signal=signal_smooth,\n        true_noise_level=noise_level,\n        interpolation=interpolation_boolean,\n        computation_threshold=computation_threshold,\n    )\n    for i in range(NUMBER_RUNS)\n]\nmodels_rough = [\n    es.ConjugateGradients(\n        design,\n        observation_rough[:, i],\n        true_signal=signal_rough,\n        true_noise_level=noise_level,\n        interpolation=interpolation_boolean,\n        computation_threshold=computation_threshold,\n    )\n    for i in range(NUMBER_RUNS)\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We calculate the early stopping index, the conjugate gradient estimate at the early stopping index and the squared residual norms along the whole iteration path (until max_iter) for the three signals.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for run in range(NUMBER_RUNS):\n    start_time = time.time()\n    models_supersmooth[run].gather_all(max_iter)\n    models_smooth[run].gather_all(max_iter)\n    models_rough[run].gather_all(max_iter)\n    end_time = time.time()\n    print(f\"The {run+1}. Monte Carlo step took {end_time - start_time} seconds.\")\n    print(f\"Supersmooth early stopping index: {models_supersmooth[run].early_stopping_index}\")\n    print(f\"Smooth early stopping index: {models_smooth[run].early_stopping_index}\")\n    print(f\"Rough early stopping index: {models_rough[run].early_stopping_index}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot of squared residual norms and empirical error terms\nWe plot for the first Monte Carlo run the squared residual norms along the whole iteration path and the corresponding weak and strong empirical error terms,\ni.e. the empirical prediction and reconstruction errors, for the supersmooth signal. The critical value is denoted by $\\kappa$ and the early stopping index by $\\tau$.\nIf we choose to interpolate, i.e. interpolation_boolean is set to\ntrue, we need to interpolate between the residual polynomials and therefore between the estimators.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set gridsize for the x-axis of the plots\nGRIDSIZE = 0.01\n\n# Calculate interpolated squared residual norms and interpolated strong and weak empirical errors for the first Monte Carlo run\nif interpolation_boolean:\n    grid = np.arange(0, max_iter + GRIDSIZE, GRIDSIZE)\n    residuals_supersmooth = models_supersmooth[0].calculate_interpolated_residual(index=grid)\n    strong_empirical_errors_supersmooth = models_supersmooth[0].calculate_interpolated_strong_empirical_error(\n        index=grid\n    )\n    weak_empirical_errors_supersmooth = models_supersmooth[0].calculate_interpolated_weak_empirical_error(index=grid)\nelse:\n    grid = np.arange(0, max_iter + 1)\n    residuals_supersmooth = models_supersmooth[0].residuals\n    strong_empirical_errors_supersmooth = models_supersmooth[0].strong_empirical_errors\n    weak_empirical_errors_supersmooth = models_supersmooth[0].weak_empirical_errors\n\n# Plot\nplot_residuals_empirical_errors = plt.figure()\nplt.plot(grid, residuals_supersmooth, label=\"squared residual norm\", color=\"green\")\nplt.plot(grid, strong_empirical_errors_supersmooth, label=\"strong empirical error\", color=\"blue\")\nplt.plot(grid, weak_empirical_errors_supersmooth, label=\"weak empirical error\", color=\"orange\")\nplt.axvline(x=models_supersmooth[0].early_stopping_index, color=\"grey\", linestyle=\"--\")\nplt.axhline(y=models_supersmooth[0].critical_value, color=\"grey\", linestyle=\"--\")\nplt.xlim([0, 14])\nplt.ylim([0, 2])\nplt.xlabel(\"Iteration index\")\nplt.xticks(list(plt.xticks()[0]) + [models_supersmooth[0].early_stopping_index], list(plt.xticks()[1]) + [\"$\\\\tau$\"])\nplt.yticks(\n    list(plt.yticks()[0]) + [models_supersmooth[0].critical_value], list(plt.yticks()[1]) + [\"$\\\\kappa = D \\\\delta^2$\"]\n)\nplt.legend()\nplt.grid()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Strong and weak empirical oracles\nWe add the strong and weak empirical oracles to the plot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Calculate the empirical oracles\nempirical_oracles_supersmooth = models_supersmooth[0].calculate_empirical_oracles(max_iter)\n\n# Update the plot\nplt.figure(plot_residuals_empirical_errors)\nplt.axvline(\n    x=empirical_oracles_supersmooth[0],\n    color=\"grey\",\n    linestyle=\"--\",\n)\nplt.xticks(\n    list(plt.xticks()[0]) + [empirical_oracles_supersmooth[0]],\n    list(plt.xticks()[1]) + [\"$\\\\tau_{emp,\\\\mathfrak{s}}$\"],\n)\nplt.axvline(\n    x=empirical_oracles_supersmooth[2],\n    color=\"grey\",\n    linestyle=\"--\",\n)\nplt.xticks(\n    list(plt.xticks()[0]) + [empirical_oracles_supersmooth[2]],\n    list(plt.xticks()[1]) + [\"$\\\\tau_{emp,\\\\mathfrak{w}}$\"],\n)\nplt.xlim([2, 8])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Boxplots of the strong and weak empirical losses\nWe make boxplots comparing the performance of the conjugate gradient estimator at the early stopping index for the three different signals in terms of its strong and weak empirical error.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if interpolation_boolean:\n    strong_empirical_errors_supersmooth_Monte_Carlo = [\n        float(model.calculate_interpolated_strong_empirical_error(index=model.early_stopping_index).item())\n        for model in models_supersmooth\n    ]\n    strong_empirical_errors_smooth_Monte_Carlo = [\n        float(model.calculate_interpolated_strong_empirical_error(index=model.early_stopping_index).item())\n        for model in models_smooth\n    ]\n    strong_empirical_errors_rough_Monte_Carlo = [\n        float(model.calculate_interpolated_strong_empirical_error(index=model.early_stopping_index).item())\n        for model in models_rough\n    ]\n    weak_empirical_errors_supersmooth_Monte_Carlo = [\n        float(model.calculate_interpolated_weak_empirical_error(index=model.early_stopping_index).item())\n        for model in models_supersmooth\n    ]\n    weak_empirical_errors_smooth_Monte_Carlo = [\n        float(model.calculate_interpolated_weak_empirical_error(index=model.early_stopping_index).item())\n        for model in models_smooth\n    ]\n    weak_empirical_errors_rough_Monte_Carlo = [\n        float(model.calculate_interpolated_weak_empirical_error(index=model.early_stopping_index).item())\n        for model in models_rough\n    ]\nelse:\n    strong_empirical_errors_supersmooth_Monte_Carlo = [\n        models_supersmooth[i].strong_empirical_errors[models_supersmooth[i].early_stopping_index]\n        for i in range(NUMBER_RUNS)\n    ]\n    strong_empirical_errors_smooth_Monte_Carlo = [\n        models_smooth[i].strong_empirical_errors[models_smooth[i].early_stopping_index] for i in range(NUMBER_RUNS)\n    ]\n    strong_empirical_errors_rough_Monte_Carlo = [\n        models_rough[i].strong_empirical_errors[models_rough[i].early_stopping_index] for i in range(NUMBER_RUNS)\n    ]\n    weak_empirical_errors_supersmooth_Monte_Carlo = [\n        models_supersmooth[i].weak_empirical_errors[models_supersmooth[i].early_stopping_index]\n        for i in range(NUMBER_RUNS)\n    ]\n    weak_empirical_errors_smooth_Monte_Carlo = [\n        models_smooth[i].weak_empirical_errors[models_smooth[i].early_stopping_index] for i in range(NUMBER_RUNS)\n    ]\n    weak_empirical_errors_rough_Monte_Carlo = [\n        models_rough[i].weak_empirical_errors[models_rough[i].early_stopping_index] for i in range(NUMBER_RUNS)\n    ]\n\n# Plot of the strong empirical errors\nstrong_empirical_errors_Monte_Carlo = pd.DataFrame(\n    {\n        \"algorithm\": [\"conjugate gradients\"] * NUMBER_RUNS,\n        \"supersmooth\": strong_empirical_errors_supersmooth_Monte_Carlo,\n        \"smooth\": strong_empirical_errors_smooth_Monte_Carlo,\n        \"rough\": strong_empirical_errors_rough_Monte_Carlo,\n    }\n)\nstrong_empirical_errors_Monte_Carlo = pd.melt(\n    strong_empirical_errors_Monte_Carlo, id_vars=\"algorithm\", value_vars=[\"supersmooth\", \"smooth\", \"rough\"]\n)\nplt.figure()\nstrong_empirical_errors_boxplot = sns.boxplot(\n    x=\"variable\", y=\"value\", data=strong_empirical_errors_Monte_Carlo, width=0.4\n)\nstrong_empirical_errors_boxplot.set(xlabel=\"Signal\", ylabel=\"Strong empirical error at $\\\\tau$\")\nplt.show()\n\n# Plot of the weak empirical errors\nweak_empirical_errors_Monte_Carlo = pd.DataFrame(\n    {\n        \"algorithm\": [\"conjugate gradients\"] * NUMBER_RUNS,\n        \"supersmooth\": weak_empirical_errors_supersmooth_Monte_Carlo,\n        \"smooth\": weak_empirical_errors_smooth_Monte_Carlo,\n        \"rough\": weak_empirical_errors_rough_Monte_Carlo,\n    }\n)\nweak_empirical_errors_Monte_Carlo = pd.melt(\n    weak_empirical_errors_Monte_Carlo, id_vars=\"algorithm\", value_vars=[\"supersmooth\", \"smooth\", \"rough\"]\n)\nplt.figure()\nweak_empirical_errors_boxplot = sns.boxplot(x=\"variable\", y=\"value\", data=weak_empirical_errors_Monte_Carlo, width=0.4)\nweak_empirical_errors_boxplot.set(xlabel=\"Signal\", ylabel=\"Weak empirical error at $\\\\tau$\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}