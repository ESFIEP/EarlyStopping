{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# This is a comparison of Landweber and conjugate gradients\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport EarlyStopping as es\nfrom scipy.sparse import dia_matrix\nimport timeit\n\nnp.random.seed(42)\nplt.rcParams.update({\"font.size\": 20})\nprint(\"The seed is 42.\")\n\n\nimport time\nimport numpy as np\nimport pandas as pd\nfrom scipy.sparse import dia_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport EarlyStopping as es\n\nsns.set_theme(style=\"ticks\")\nnp.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulation Setting\nTo make our results comparable, we use the same simulation setting as [Blanchard et al. (2018)](https://doi.org/10.1137/17M1154096) and [Stankewitz (2020)](https://doi.org/10.1214/20-EJS1747).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set parameters\nsample_size = 1000\nparameter_size = sample_size\nmax_iter = sample_size\nnoise_level = 0.01\ncritical_value = sample_size * (noise_level**2)\n\n# Create diagonal design matrices\nindices = np.arange(sample_size) + 1\ndesign = dia_matrix(np.diag(1 / (np.sqrt(indices))))\n\n# Create signals\nsignal_supersmooth = 5 * np.exp(-0.1 * indices)\nsignal_smooth = 5000 * np.abs(np.sin(0.01 * indices)) * indices ** (-1.6)\nsignal_rough = 250 * np.abs(np.sin(0.002 * indices)) * indices ** (-0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We plot the SVD coefficients of the three signals.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(indices, signal_supersmooth, label=\"supersmooth signal\")\nplt.plot(indices, signal_smooth, label=\"smooth signal\")\nplt.plot(indices, signal_rough, label=\"rough signal\")\nplt.ylabel(\"Signal\")\nplt.xlabel(\"Index\")\nplt.ylim([-0.05, 1.6])\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monte Carlo Study\nWe simulate NUMBER_RUNS realisations of the Gaussian sequence space model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Specify number of Monte Carlo runs\nNUMBER_RUNS = 10\n\n# Set computation threshold\ncomputation_threshold = 0\n\n# Create observations for the three different signals\nnoise = np.random.normal(0, noise_level, (sample_size, NUMBER_RUNS))\nobservation_supersmooth = noise + (design @ signal_supersmooth)[:, None]\nobservation_smooth = noise + (design @ signal_smooth)[:, None]\nobservation_rough = noise + (design @ signal_rough)[:, None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We choose to interpolate linearly between the conjugate gradient estimates at integer iteration indices and create the models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set interpolation boolean\ninterpolation_boolean = False\n\nsupersmooth_strong_empirical_error_cg = np.zeros(NUMBER_RUNS)\nsmooth_strong_empirical_error_cg = np.zeros(NUMBER_RUNS)\nrough_strong_empirical_error_cg = np.zeros(NUMBER_RUNS)\nsupersmooth_weak_empirical_error_cg = np.zeros(NUMBER_RUNS)\nsmooth_weak_empirical_error_cg = np.zeros(NUMBER_RUNS)\nrough_weak_empirical_error_cg = np.zeros(NUMBER_RUNS)\n\nsupersmooth_strong_empirical_error_landweber = np.zeros(NUMBER_RUNS)\nsmooth_strong_empirical_error_landweber = np.zeros(NUMBER_RUNS)\nrough_strong_empirical_error_landweber = np.zeros(NUMBER_RUNS)\nsupersmooth_weak_empirical_error_landweber = np.zeros(NUMBER_RUNS)\nsmooth_weak_empirical_error_landweber = np.zeros(NUMBER_RUNS)\nrough_weak_empirical_error_landweber = np.zeros(NUMBER_RUNS)\n\n# Loop over the NUMBER_RUNS\nfor i in range(NUMBER_RUNS):\n    # Create models for the supersmooth signal using Conjugate Gradients\n    models_supersmooth_cg = es.ConjugateGradients(\n        design,\n        observation_supersmooth[:, i],\n        true_signal=signal_supersmooth,\n        true_noise_level=noise_level,\n        interpolation=interpolation_boolean,\n        computation_threshold=computation_threshold,\n    )\n\n    # Create models for the smooth signal using Conjugate Gradients\n    models_smooth_cg = es.ConjugateGradients(\n        design,\n        observation_smooth[:, i],\n        true_signal=signal_smooth,\n        true_noise_level=noise_level,\n        interpolation=interpolation_boolean,\n        computation_threshold=computation_threshold,\n    )\n\n    # Create models for the rough signal using Conjugate Gradients\n    models_rough_cg = es.ConjugateGradients(\n        design,\n        observation_rough[:, i],\n        true_signal=signal_rough,\n        true_noise_level=noise_level,\n        interpolation=interpolation_boolean,\n        computation_threshold=computation_threshold,\n    )\n\n    # Create models for the supersmooth signal using Landweber\n    models_supersmooth_landweber = es.Landweber(\n        design, observation_supersmooth[:, i], true_signal=signal_supersmooth, true_noise_level=noise_level\n    )\n\n    # Create models for the smooth signal using Landweber\n    models_smooth_landweber = es.Landweber(\n        design, observation_smooth[:, i], true_signal=signal_smooth, true_noise_level=noise_level\n    )\n\n    # Create models for the rough signal using Landweber\n    models_rough_landweber = es.Landweber(\n        design, observation_rough[:, i], true_signal=signal_rough, true_noise_level=noise_level\n    )\n\n    # Gather all estimates for the Conjugate Gradients models\n    models_supersmooth_cg.gather_all(max_iter)\n    models_smooth_cg.gather_all(max_iter)\n    models_rough_cg.gather_all(max_iter)\n\n    # Iterate Landweber models for max_iter iterations\n    models_supersmooth_landweber.iterate(max_iter)\n    models_smooth_landweber.iterate(max_iter)\n    models_rough_landweber.iterate(max_iter)\n\n    # Calculate the strong empirical errors for Landweber estimates of the supersmooth signal\n    supersmooth_strong_empirical_error_landweber[i] = np.sum(\n        (\n            (\n                models_supersmooth_landweber.landweber_estimate_collect[\n                    models_supersmooth_landweber.early_stopping_index\n                ]\n                - models_supersmooth_landweber.true_signal\n            )\n        )\n        ** 2\n    )\n\n    # Calculate the strong empirical errors for Landweber estimates of the smooth signal\n    smooth_strong_empirical_error_landweber[i] = np.sum(\n        (\n            (\n                models_smooth_landweber.landweber_estimate_collect[models_smooth_landweber.early_stopping_index]\n                - models_smooth_landweber.true_signal\n            )\n        )\n        ** 2\n    )\n\n    # Calculate the strong empirical errors for Landweber estimates of the rough signal\n    rough_strong_empirical_error_landweber[i] = np.sum(\n        (\n            (\n                models_rough_landweber.landweber_estimate_collect[models_rough_landweber.early_stopping_index]\n                - models_rough_landweber.true_signal\n            )\n        )\n        ** 2\n    )\n\n    # Get the strong empirical errors for Conjugate Gradients estimates of the supersmooth signal\n    supersmooth_strong_empirical_error_cg[i] = models_supersmooth_cg.strong_empirical_errors[\n        models_supersmooth_cg.early_stopping_index\n    ]\n\n    # Get the strong empirical errors for Conjugate Gradients estimates of the smooth signal\n    smooth_strong_empirical_error_cg[i] = models_smooth_cg.strong_empirical_errors[\n        models_smooth_cg.early_stopping_index\n    ]\n\n    # Get the strong empirical errors for Conjugate Gradients estimates of the rough signal\n    rough_strong_empirical_error_cg[i] = models_rough_cg.strong_empirical_errors[models_rough_cg.early_stopping_index]\n\n    # WEAK EMPIRICAL ERRORS\n    # Calculate the weak empirical errors for Landweber estimates of the supersmooth signal\n    supersmooth_weak_empirical_error_landweber[i] = np.sum(\n        (\n            design\n            @ (\n                models_supersmooth_landweber.landweber_estimate_collect[\n                    models_supersmooth_landweber.early_stopping_index\n                ]\n                - models_supersmooth_landweber.true_signal\n            )\n        )\n        ** 2\n    )\n\n    #  Calculate the weak empirical errors for Landweber estimates of the smooth signal\n    smooth_weak_empirical_error_landweber[i] = np.sum(\n        (\n            design\n            @ (\n                models_smooth_landweber.landweber_estimate_collect[models_smooth_landweber.early_stopping_index]\n                - models_smooth_landweber.true_signal\n            )\n        )\n        ** 2\n    )\n\n    # Calculate the weak empirical errors for Landweber estimates of the rough signal\n    rough_weak_empirical_error_landweber[i] = np.sum(\n        (\n            design\n            @ (\n                models_rough_landweber.landweber_estimate_collect[models_rough_landweber.early_stopping_index]\n                - models_rough_landweber.true_signal\n            )\n        )\n        ** 2\n    )\n\n    # Get the weak empirical errors for Conjugate Gradients estimates of the supersmooth signal\n    supersmooth_weak_empirical_error_cg[i] = models_supersmooth_cg.weak_empirical_errors[\n        models_supersmooth_cg.early_stopping_index\n    ]\n\n    # Get the weak empirical errors for Conjugate Gradients estimates of the smooth signal\n    smooth_weak_empirical_error_cg[i] = models_smooth_cg.weak_empirical_errors[models_smooth_cg.early_stopping_index]\n\n    # Get the weak empirical errors for Conjugate Gradients estimates of the rough signal\n    rough_weak_empirical_error_cg[i] = models_rough_cg.weak_empirical_errors[models_rough_cg.early_stopping_index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strong Empirical Errors\nWe plot the strong empirical errors of the conjugate gradient and Landweber estimates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "strong_empirical_errors_Monte_Carlo = pd.DataFrame(\n    {\n        # \"algorithm\": [\"conjugate gradients\"] * NUMBER_RUNS,\n        \"supersmooth_cg\": supersmooth_strong_empirical_error_cg,\n        \"supersmooth_landweber\": supersmooth_strong_empirical_error_landweber,\n        \"smooth_cg\": smooth_strong_empirical_error_cg,\n        \"smooth_landweber\": smooth_strong_empirical_error_landweber,\n        \"rough_cg\": rough_strong_empirical_error_cg,\n        \"rough_landweber\": rough_strong_empirical_error_landweber,\n    }\n)\n\nstrong_empirical_errors_Monte_Carlo = pd.melt(\n    strong_empirical_errors_Monte_Carlo,\n    # id_vars=\"algorithm\",\n    value_vars=[\n        \"supersmooth_cg\",\n        \"supersmooth_landweber\",\n        \"smooth_cg\",\n        \"smooth_landweber\",\n        \"rough_cg\",\n        \"rough_landweber\",\n    ],\n)\n\nplt.figure(figsize=(14, 10))\nstrong_empirical_errors_boxplot = sns.boxplot(\n    x=\"variable\",\n    y=\"value\",\n    data=strong_empirical_errors_Monte_Carlo,\n    width=0.8,\n    palette=[\"tab:purple\", \"tab:purple\", \"tab:orange\", \"tab:orange\", \"tab:blue\", \"tab:blue\"],\n)\nstrong_empirical_errors_boxplot.set_ylabel(\"Strong Empirical Error at $\\\\tau$\", fontsize=24)  # Increase fontsize\nstrong_empirical_errors_boxplot.set_xlabel(\"Data generating processes\", fontsize=24)  # Increase fontsize\nstrong_empirical_errors_boxplot.set_xticklabels(strong_empirical_errors_boxplot.get_xticklabels(), rotation=45)\n\nstrong_empirical_errors_boxplot.tick_params(axis=\"both\", which=\"major\", labelsize=24)  # Increase fontsize\nplt.title(\"Comparison of Strong Empirical Errors\", fontsize=28)  # Increase title fontsize\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Weak Empirical Errors\nWe plot the weak empirical errors of the conjugate gradient and Landweber estimates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "weak_empirical_errors_Monte_Carlo = pd.DataFrame(\n    {\n        # \"algorithm\": [\"conjugate gradients\"] * NUMBER_RUNS,\n        \"supersmooth_cg\": supersmooth_weak_empirical_error_cg,\n        \"supersmooth_landweber\": supersmooth_weak_empirical_error_landweber,\n        \"smooth_cg\": smooth_weak_empirical_error_cg,\n        \"smooth_landweber\": smooth_weak_empirical_error_landweber,\n        \"rough_cg\": rough_weak_empirical_error_cg,\n        \"rough_landweber\": rough_weak_empirical_error_landweber,\n    }\n)\n\nweak_empirical_errors_Monte_Carlo = pd.melt(\n    weak_empirical_errors_Monte_Carlo,\n    # id_vars=\"algorithm\",\n    value_vars=[\n        \"supersmooth_cg\",\n        \"supersmooth_landweber\",\n        \"smooth_cg\",\n        \"smooth_landweber\",\n        \"rough_cg\",\n        \"rough_landweber\",\n    ],\n)\n\nplt.figure(figsize=(14, 10))\nweak_empirical_errors_boxplot = sns.boxplot(\n    x=\"variable\",\n    y=\"value\",\n    data=weak_empirical_errors_Monte_Carlo,\n    width=0.8,\n    palette=[\"tab:purple\", \"tab:purple\", \"tab:orange\", \"tab:orange\", \"tab:blue\", \"tab:blue\"],\n)\nweak_empirical_errors_boxplot.set_ylabel(\"Weak Empirical Error at $\\\\tau$\", fontsize=24)  # Increase fontsize\nweak_empirical_errors_boxplot.set_xlabel(\"Data generating processes\", fontsize=24)  # Increase fontsize\nweak_empirical_errors_boxplot.set_xticklabels(weak_empirical_errors_boxplot.get_xticklabels(), rotation=45)\n\nweak_empirical_errors_boxplot.tick_params(axis=\"both\", which=\"major\", labelsize=24)  # Increase fontsize\nplt.title(\"Comparison of Weak Empirical Errors\", fontsize=28)  # Increase title fontsize\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Montecarlo simmulation for the gravity example\nGravity test problem from the regtools toolbox, see [Hansen (2008)](http://people.compute.dtu.dk/pcha/Regutools/RTv4manual.pdf) for details.\nPlot the residuals, weak and strong quantities.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sample_size_gravity = 100  # 2**9\na = 0\nb = 1\nd = 0.25  # Parameter controlling the ill-posedness: the larger, the more ill-posed, default in regtools: d = 0.25\n\nt = (np.arange(1, sample_size_gravity + 1) - 0.5) / sample_size_gravity\ns = ((np.arange(1, sample_size_gravity + 1) - 0.5) * (b - a)) / sample_size_gravity\nT, S = np.meshgrid(t, s)\n\ndesign_gravity = (\n    (1 / sample_size_gravity)\n    * d\n    * (d**2 * np.ones((sample_size_gravity, sample_size_gravity)) + (S - T) ** 2) ** (-(3 / 2))\n)\nsignal_gravity = np.sin(np.pi * t) + 0.5 * np.sin(2 * np.pi * t)\ndesign_times_signal = design_gravity @ signal_gravity\n\n# Set parameters\nparameter_size = sample_size_gravity\nmax_iter = 10000\nnoise_level = 10 ** (-2)\n\n# Specify number of Monte Carlo runs\nNUMBER_RUNS = 10\n\n# Create observations\nnoise = np.random.normal(0, noise_level, (sample_size_gravity, NUMBER_RUNS))\nobservation_gravity = noise + design_times_signal[:, None]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We choose to interpolate linearly between the conjugate gradient estimates at integer iteration indices and create the models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gravity_strong_empirical_error_cg = np.zeros(NUMBER_RUNS)\ngravity_weak_empirical_error_cg = np.zeros(NUMBER_RUNS)\n\ngravity_strong_empirical_error_landweber = np.zeros(NUMBER_RUNS)\ngravity_weak_empirical_error_landweber = np.zeros(NUMBER_RUNS)\n\ncount_landweber_fails = 0\n\nfor i in range(NUMBER_RUNS):\n    # Create models for the gravity signal using Conjugate Gradients\n    models_gravity_cg = es.ConjugateGradients(\n        design_gravity,\n        observation_gravity[:, i],\n        true_signal=signal_gravity,\n        true_noise_level=noise_level,\n        interpolation=interpolation_boolean,\n        computation_threshold=computation_threshold,\n    )\n\n    #  Create models for the gravity signal using Landweber\n    models_gravity_landweber = es.Landweber(\n        design_gravity,\n        observation_gravity[:, i],\n        true_signal=signal_gravity,\n        learning_rate=1 / 30,\n        true_noise_level=noise_level,\n    )\n\n    # Gather all estimates for the Conjugate Gradients models\n    models_gravity_cg.gather_all(max_iter)\n\n    # Iterate Landweber models for max_iter iterations\n    models_gravity_landweber.iterate(max_iter)\n\n    if models_gravity_landweber.early_stopping_index == None:\n        count_landweber_fails += 1\n        continue\n\n    # Get the strong empirical errors for Conjugate Gradients estimates of the gravity signal\n    gravity_strong_empirical_error_cg[i] = models_gravity_cg.strong_empirical_errors[\n        models_gravity_cg.early_stopping_index\n    ]\n\n    # Get the weak empirical errors for Conjugate Gradients estimates of the gravity signal\n    gravity_weak_empirical_error_cg[i] = models_gravity_cg.weak_empirical_errors[models_gravity_cg.early_stopping_index]\n\n    gravity_weak_empirical_error_landweber[i] = np.sum(\n        (\n            design_gravity\n            @ (\n                models_gravity_landweber.landweber_estimate_collect[models_gravity_landweber.early_stopping_index]\n                - models_gravity_landweber.true_signal\n            )\n        )\n        ** 2\n    )\n\n    gravity_strong_empirical_error_landweber[i] = np.sum(\n        (\n            (\n                models_gravity_landweber.landweber_estimate_collect[models_gravity_landweber.early_stopping_index]\n                - models_gravity_landweber.true_signal\n            )\n        )\n        ** 2\n    )\n\nprint(f\"Landweber failed {count_landweber_fails} attempts out of {NUMBER_RUNS}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Strong Empirical Errors Gravity\nWe plot the strong empirical errors of the conjugate gradient and Landweber estimates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "strong_empirical_errors_Monte_Carlo = pd.DataFrame(\n    {\n        # \"algorithm\": [\"conjugate gradients\"] * NUMBER_RUNS,\n        \"gravity_cg\": gravity_strong_empirical_error_cg,\n        \"gravity_landweber\": gravity_strong_empirical_error_landweber,\n    }\n)\n\nstrong_empirical_errors_Monte_Carlo = pd.melt(\n    strong_empirical_errors_Monte_Carlo,\n    # id_vars=\"algorithm\",\n    value_vars=[\"gravity_cg\", \"gravity_landweber\"],\n)\n\nplt.figure(figsize=(14, 10))\nstrong_empirical_errors_boxplot = sns.boxplot(\n    x=\"variable\",\n    y=\"value\",\n    data=strong_empirical_errors_Monte_Carlo,\n    width=0.8,\n    palette=[\"tab:purple\", \"tab:purple\"],\n)\nstrong_empirical_errors_boxplot.set_ylabel(\"Strong Empirical Error at $\\\\tau$\", fontsize=24)  # Increase fontsize\nstrong_empirical_errors_boxplot.set_xlabel(\"Data generating processes\", fontsize=24)  # Increase fontsize\nstrong_empirical_errors_boxplot.set_xticklabels(strong_empirical_errors_boxplot.get_xticklabels(), rotation=45)\n\nstrong_empirical_errors_boxplot.tick_params(axis=\"both\", which=\"major\", labelsize=24)  # Increase fontsize\nplt.title(\"Comparison of Strong Empirical Errors - Gravity\", fontsize=28)  # Increase title fontsize\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Weak Empirical Errors Gravity\nWe plot the weak empirical errors of the conjugate gradient and Landweber estimates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "weak_empirical_errors_Monte_Carlo = pd.DataFrame(\n    {\n        # \"algorithm\": [\"conjugate gradients\"] * NUMBER_RUNS,\n        \"gravity_cg\": gravity_weak_empirical_error_cg,\n        \"gravity_landweber\": gravity_weak_empirical_error_landweber,\n    }\n)\n\nweak_empirical_errors_Monte_Carlo = pd.melt(\n    weak_empirical_errors_Monte_Carlo,\n    # id_vars=\"algorithm\",\n    value_vars=[\"gravity_cg\", \"gravity_landweber\"],\n)\n\nplt.figure(figsize=(14, 10))\nweak_empirical_errors_boxplot = sns.boxplot(\n    x=\"variable\",\n    y=\"value\",\n    data=weak_empirical_errors_Monte_Carlo,\n    width=0.8,\n    palette=[\"tab:purple\", \"tab:purple\"],\n)\nweak_empirical_errors_boxplot.set_ylabel(\"weak Empirical Error at $\\\\tau$\", fontsize=24)  # Increase fontsize\nweak_empirical_errors_boxplot.set_xlabel(\"Data generating processes\", fontsize=24)  # Increase fontsize\nweak_empirical_errors_boxplot.set_xticklabels(weak_empirical_errors_boxplot.get_xticklabels(), rotation=45)\n\nweak_empirical_errors_boxplot.tick_params(axis=\"both\", which=\"major\", labelsize=24)  # Increase fontsize\nplt.title(\"Comparison of weak Empirical Errors - Gravity\", fontsize=28)  # Increase title fontsize\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}